{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from operator import add\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.sql.functions import col, udf, ltrim , rtrim\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from gensim.models import KeyedVectors\n",
    "from pyspark.sql.functions import UserDefinedFunction\n",
    "from pyspark.sql.types import IntegerType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"QuoraInsincere\")\\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv( \"/home/akash/project/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = corpus.toDF(\"qid\",\"question_text\",\"target\")\n",
    "#data = data.limit(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(x):  \n",
    "    for punct in \"/-'\":\n",
    "        x = x.replace(punct, ' ')\n",
    "    for punct in '&':\n",
    "        x = x.replace(punct, r' {punct} ')\n",
    "    for punct in '?!.,\"#$%\\'()*+:;<=>@[\\\\]^_`{|}~':\n",
    "        x = x.replace(punct, '')\n",
    "    return x\n",
    "udfClean = udf(lambda x: clean_text(x),StringType())\n",
    "#clean_text(\"Is it just me or have you ever been in this phase wherein you became ignorant to the people you once loved, completely disregarding their feelings/lives so you get to have something go your way and feel temporarily at ease. How did things change?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nonasciitoascii(unicodestring):\n",
    "    return unicodestring.encode(\"ascii\",\"ignore\")\n",
    "convertedudf = udf(nonasciitoascii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_numbers(x):\n",
    "\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x\n",
    "udfCleanNum = udf(lambda x: clean_numbers(x),StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.where(data['question_text'] != \"\")\n",
    "data = data.withColumn('question_text',convertedudf(data.question_text))\n",
    "data = data.withColumn('question_text', ltrim(data.question_text))\n",
    "data = data.withColumn('question_text', rtrim(data.question_text))\n",
    "\n",
    "#data=data.withColumn('question_text',commaRep(data.question_text))\n",
    "#data=data.withColumn('question_text', regexp_replace('question_text', ',', ''))\n",
    "#data.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn('question_text', udfClean(data.question_text))\n",
    "#data = data.withColumn('question_text', udfCleanNum(data.question_text))\n",
    "#data.show(truncate= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
      "|qid                 |question_text                                                                                                                                                                                                                                      |target|\n",
      "+--------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
      "|00002165364db923c7e6|How did Quebec nationalists see their province as a nation in the 1960s                                                                                                                                                                            |0     |\n",
      "|000032939017120e6e44|Do you have an adopted dog how would you encourage people to adopt and not shop                                                                                                                                                                    |0     |\n",
      "|0000412ca6e4628ce2cf|Why does velocity affect time Does velocity affect space geometry                                                                                                                                                                                  |0     |\n",
      "|000042bf85aa498cd78e|How did Otto von Guericke used the Magdeburg hemispheres                                                                                                                                                                                           |0     |\n",
      "|0000455dfa3e01eae3af|Can I convert montra helicon D to a mountain bike by just changing the tyres                                                                                                                                                                       |0     |\n",
      "|00004f9a462a357c33be|Is Gaza slowly becoming Auschwitz Dachau or Treblinka for Palestinians                                                                                                                                                                             |0     |\n",
      "|00005059a06ee19e11ad|Why does Quora automatically ban conservative opinions when reported but does not do the same for liberal views                                                                                                                                    |0     |\n",
      "|0000559f875832745e2e|Is it crazy if I wash or wipe my groceries off Germs are everywhere                                                                                                                                                                                |0     |\n",
      "|00005bd3426b2d0c8305|Is there such a thing as dressing moderately and if so how is that different than dressing modestly                                                                                                                                                |0     |\n",
      "|00006e6928c5df60eacb|Is it just me or have you ever been in this phase wherein you became ignorant to the people you once loved completely disregarding their feelings lives so you get to have something go your way and feel temporarily at ease How did things change|0     |\n",
      "|000075f67dd595c3deb5|What can you say about feminism                                                                                                                                                                                                                    |0     |\n",
      "|000076f3b42776c692de|How were the Calgary Flames founded                                                                                                                                                                                                                |0     |\n",
      "|000089792b3fc8026741|What is the dumbest yet possibly true explanation for Trump being elected                                                                                                                                                                          |0     |\n",
      "|000092a90bcfbfe8cd88|Can we use our external hard disk as a OS as well as for data storagewill the data be affected                                                                                                                                                     |0     |\n",
      "|000095680e41a9a6f6e3|I am 30 living at home and have no boyfriend I would love a boyfriend and my own home How can I progress my situation                                                                                                                              |0     |\n",
      "|0000a89942e3143e333a|What do you know about Bram Fischer and the Rivonia Trial                                                                                                                                                                                          |0     |\n",
      "|0000b8e1279eaa0a7062|How difficult is it to find a good instructor to take a class near you                                                                                                                                                                             |0     |\n",
      "|0000bc0f62500f55959f|Have you licked the skin of a corpse                                                                                                                                                                                                               |0     |\n",
      "|0000ce6c31f14d3e09ec|Do you think Amazon will adopt an in house approach to manufacturing similar to the Tesla or Space X business models                                                                                                                               |0     |\n",
      "|0000d329332845b8a7fa|How many baronies might exist within a county palatine                                                                                                                                                                                             |0     |\n",
      "+--------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"question_text\", outputCol=\"words\")\n",
    "tokenized = tokenizer.transform(data)\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "cleanData = remover.transform(tokenized)\n",
    "cleanData = cleanData.select(\"filtered\",\"target\")#.limit(300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2Vec = Word2Vec(vectorSize=100, minCount=2, inputCol=\"filtered\", outputCol=\"wordvectors\")\n",
    "model = word2Vec.fit(cleanData)\n",
    "\n",
    "result = model.transform(cleanData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import IDF, CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"rawFeatures\")\n",
    "\n",
    "cvmodel = cv.fit(result)\n",
    "\n",
    "featurizedData = cvmodel.transform(result)\n",
    "#featurizedData.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "rescaledData = rescaledData.select(\"filtered\",\"wordvectors\",\"features\",\"target\")\n",
    "#rescaledData.select(\"filtered\", \"features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import LDA\n",
    "def train_LDA(dataset):\n",
    "    num_topics = 20\n",
    "    max_iterations = 100\n",
    "    lda = LDA(k=num_topics, maxIter=max_iterations)\n",
    "    model = lda.fit(dataset.select(\"filtered\", \"features\", \"wordvectors\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sincere = rescaledData.where(rescaledData[\"target\"]==0)\n",
    "modelSincere = train_LDA(sincere)\n",
    "topicSincere = modelSincere.describeTopics(1)\n",
    "#print(\"The topics described by their top-weighted terms :\")\n",
    "#topicSincere.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "insincere = rescaledData.where(rescaledData[\"target\"]==1)\n",
    "modelInsincere = train_LDA(insincere)\n",
    "topicInsincere = modelInsincere.describeTopics(5)\n",
    "#print(\"The topics described by their top-weighted terms for sincere questions:\")\n",
    "#topicInsincere.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "def indices_to_terms(vocabulary):\n",
    "    def indices_to_terms(xs):\n",
    "        return [vocabulary[int(x)] for x in xs]\n",
    "    return udf(indices_to_terms, ArrayType(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topicSincere.withColumn(\"topics_words\", indices_to_terms(cvmodel.vocabulary)(\"termIndices\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topicInsincere.withColumn(\"topics_words\", indices_to_terms(cvmodel.vocabulary)(\"termIndices\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformedSincere = modelSincere.transform(rescaledData.where(rescaledData[\"target\"]==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformedInsincere =  modelInsincere.transform(rescaledData.where(rescaledData[\"target\"]==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformedSincere.where(transformedSincere['target']==1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "import numpy as np\n",
    "def findTopicSincere(topicDistribution):\n",
    "    zero = np.zeros(20)\n",
    "    return np.concatenate((topicDistribution, zero)).tolist()\n",
    "def findTopicInsincere(topicDistribution):\n",
    "    zero = np.zeros(20)\n",
    "    return np.concatenate((zero, topicDistribution)).tolist()\n",
    "udfFindTopicSincere = udf(lambda z  :findTopicSincere(z), ArrayType(FloatType()))\n",
    "udfFindTopicInsincere = udf(lambda z  :findTopicInsincere(z), ArrayType(FloatType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smallDataset = transformedSincere.select(transformedSincere.topicDistribution, transformedSincere.target).limit(50)\n",
    "#smallDataset = smallDataset.withColumn(\"topic\", udfFindTopicSincere(smallDataset.topicDistribution))\n",
    "#smallDataset.show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# smallDataset = smallDataset.withColumn(\"topic\", udfFindTopicSincere(smallDataset.topicDistribution))\n",
    "# smallDataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smallDataset.show()\n",
    "topicSincere = transformedSincere.withColumn(\"topic\", udfFindTopicSincere(transformedSincere.topicDistribution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "topicInsincere = transformedInsincere.withColumn(\"topic\", udfFindTopicInsincere(transformedInsincere.topicDistribution))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topicSincere = topicSincere.select(\"wordvectors\", \"topic\",\"target\")\n",
    "topicInsincere = topicInsincere.select(\"wordvectors\", \"topic\",\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#topicInsincere.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset = topicSincere.union(topicInsincere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|         wordvectors|               topic|target|\n",
      "+--------------------+--------------------+------+\n",
      "|[-2.2017961600795...|[0.0012961242, 0....|     0|\n",
      "|[-4.2312196455895...|[0.0013636403, 0....|     0|\n",
      "|[1.08727187450442...|[0.0011268969, 0....|     0|\n",
      "|[-7.8273618904252...|[0.0013095796, 0....|     0|\n",
      "|[0.0,0.0,0.0,0.0,...|[9.645319E-4, 0.0...|     0|\n",
      "|[0.0,0.0,0.0,0.0,...|[0.0010992176, 0....|     0|\n",
      "|[-9.4036164227873...|[9.857783E-4, 0.0...|     0|\n",
      "|[6.25436194241046...|[0.0012961242, 0....|     0|\n",
      "|[-6.6072850798567...|[0.0013202104, 0....|     0|\n",
      "|[2.58596948697231...|[4.2476767E-4, 4....|     0|\n",
      "|[0.00149994099047...|[0.0037965977, 0....|     0|\n",
      "|[0.0,0.0,0.0,0.0,...|[0.0024900353, 0....|     0|\n",
      "|[2.82822708998407...|[0.0011128852, 0....|     0|\n",
      "|[0.00106573990778...|[0.0954127, 8.633...|     0|\n",
      "|[-2.8969088452868...|[9.0640347E-4, 9....|     0|\n",
      "|[-8.3318399265408...|[0.0016280704, 0....|     0|\n",
      "|[-0.0014871781791...|[0.0011902767, 0....|     0|\n",
      "|[2.90647614747285...|[0.0025612914, 0....|     0|\n",
      "|[1.53771211140944...|[6.8687444E-4, 7....|     0|\n",
      "|[-4.6049570664763...|[0.0011370544, 0....|     0|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "traindataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'question_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b13e98b85e08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraindataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'question_text'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconvertedudf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestion_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconverted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/akash/anaconda2/lib/python2.7/site-packages/pyspark/sql/dataframe.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m             raise AttributeError(\n\u001b[0;32m-> 1182\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[1;32m   1183\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'question_text'"
     ]
    }
   ],
   "source": [
    "#converted = traindataset.withColumn('question_text',convertedudf(traindataset.question_text))\n",
    "#converted.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindataset.toPandas().to_csv('traindataset3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "# from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "# # specify layers for the neural network:\n",
    "# # input layer of size 4 (features), two intermediate of size 5 and 4\n",
    "# # and output of size 3 (classes)\n",
    "# layers = [4, 5, 4, 3]\n",
    "\n",
    "# # create the trainer and set its parameters\n",
    "# trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "\n",
    "# trainer.setFeaturesCol(\"result\")\n",
    "# trainer.setLabelCol(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import FeatureHasher\n",
    "# hasher = FeatureHasher(inputCols=[\"filtered\", \"topic\"],\n",
    "#                        outputCol=\"hashedfeatures\")\n",
    "\n",
    "# featurized = hasher.transform(trainset)\n",
    "# featurized.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train the model\n",
    "# model = trainer.fit(trainset)\n",
    "\n",
    "# # compute accuracy on the test set\n",
    "# result = model.transform(traindataset)\n",
    "# predictionAndLabels = result.select(\"prediction\", \"target\")\n",
    "# evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "# print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero = np.zeros(5, dtype = int)\n",
    "# zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = [[[1,2,3]],[[4,5,6]],[[7,8,9]]]\n",
    "# x = spark.createDataFrame(x)\n",
    "# x.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = x.withColumn(\"_2\", udfFindTopicSincere(x._1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
