{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import sys\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "from operator import add\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(\"QuoraInsincere\")\\\n",
    "        .getOrCreate()\n",
    "# conf = SparkConf().setMaster(\"local\").setAppName(\"sample\")\n",
    "# sc = SparkContext(conf=conf)\n",
    "# conf = spark.conf\n",
    "# sc = SparkContext(conf)\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|                 qid|       question_text|target|\n",
      "+--------------------+--------------------+------+\n",
      "|00002165364db923c7e6|How did Quebec na...|     0|\n",
      "|000032939017120e6e44|Do you have an ad...|     0|\n",
      "|0000412ca6e4628ce2cf|Why does velocity...|     0|\n",
      "|000042bf85aa498cd78e|How did Otto von ...|     0|\n",
      "|0000455dfa3e01eae3af|Can I convert mon...|     0|\n",
      "|00004f9a462a357c33be|Is Gaza slowly be...|     0|\n",
      "|00005059a06ee19e11ad|Why does Quora au...|     0|\n",
      "|0000559f875832745e2e|Is it crazy if I ...|     0|\n",
      "|00005bd3426b2d0c8305|Is there such a t...|     0|\n",
      "|00006e6928c5df60eacb|Is it just me or ...|     0|\n",
      "|000075f67dd595c3deb5|What can you say ...|     0|\n",
      "|000076f3b42776c692de|How were the Calg...|     0|\n",
      "|000089792b3fc8026741|What is the dumbe...|     0|\n",
      "|000092a90bcfbfe8cd88|Can we use our ex...|     0|\n",
      "|000095680e41a9a6f6e3|I am 30, living a...|     0|\n",
      "|0000a89942e3143e333a|What do you know ...|     0|\n",
      "|0000b8e1279eaa0a7062|How difficult is ...|     0|\n",
      "|0000bc0f62500f55959f|Have you licked t...|     0|\n",
      "|0000ce6c31f14d3e09ec|Do you think Amaz...|     0|\n",
      "|0000d329332845b8a7fa|How many baronies...|     0|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus = spark.read.option(\"header\",\"true\").option(\"inferSchema\",\"true\").csv(\"data/small.csv\")\n",
    "data = corpus.select('qid','question_text','target')\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(sentences, verbose =  True):\n",
    "    \"\"\"\n",
    "    :param sentences: list of list of words\n",
    "    :return: dictionary of words and their count\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "    for sentence in sentences:\n",
    "        for word in str(sentence[0]).split():\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = corpus.select('question_text').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'How': 188, 'did': 23, 'Quebec': 1, 'nationalists': 1, 'see': 6}\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab(sentences)\n",
    "print({k: vocab[k] for k in list(vocab)[:5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_path = '/Users/ruolanzeng/InsincereQuestionClassification/data/embeddings/GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin'\n",
    "embeddings_index = KeyedVectors.load_word2vec_format(news_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator \n",
    "\n",
    "def check_coverage(vocab,embeddings_index):\n",
    "    a = {}\n",
    "    oov = {}\n",
    "    k = 0\n",
    "    i = 0\n",
    "    for word in vocab:\n",
    "        try:\n",
    "            a[word] = embeddings_index[word]\n",
    "            k += vocab[word]\n",
    "        except:\n",
    "\n",
    "            oov[word] = vocab[word]\n",
    "            i += vocab[word]\n",
    "            pass\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n",
    "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
    "\n",
    "    return sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 67.35% of vocab\n",
      "Found embeddings for  78.86% of all text\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab,embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 299),\n",
       " ('a', 296),\n",
       " ('of', 242),\n",
       " ('and', 208),\n",
       " ('it?', 15),\n",
       " ('India?', 13),\n",
       " ('\"What', 11),\n",
       " ('do?', 7),\n",
       " ('\"Why', 6),\n",
       " ('today?', 6)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(x):\n",
    "    for punct in \"/-'\":\n",
    "        x = str(x).replace(punct, ' ')\n",
    "    for punct in '&':\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    for punct in '?!.,\"#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~' + '“”’':\n",
    "        x = x.replace(punct, '')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "col should be Column",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-7db5d5678e6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'question_text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestion_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   1617\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1618\u001b[0m         \"\"\"\n\u001b[0;32m-> 1619\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"col should be Column\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1620\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: col should be Column"
     ]
    }
   ],
   "source": [
    "data = data.withColumn('question_text', clean_text(data.question_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------+\n",
      "|                 qid|       question_text|target|\n",
      "+--------------------+--------------------+------+\n",
      "|00002165364db923c7e6|how did quebec na...|     0|\n",
      "|000032939017120e6e44|do you have an ad...|     0|\n",
      "|0000412ca6e4628ce2cf|why does velocity...|     0|\n",
      "|000042bf85aa498cd78e|how did otto von ...|     0|\n",
      "|0000455dfa3e01eae3af|can i convert mon...|     0|\n",
      "|00004f9a462a357c33be|is gaza slowly be...|     0|\n",
      "|00005059a06ee19e11ad|why does quora au...|     0|\n",
      "|0000559f875832745e2e|is it crazy if i ...|     0|\n",
      "|00005bd3426b2d0c8305|is there such a t...|     0|\n",
      "|00006e6928c5df60eacb|is it just me or ...|     0|\n",
      "|000075f67dd595c3deb5|what can you say ...|     0|\n",
      "|000076f3b42776c692de|how were the calg...|     0|\n",
      "|000089792b3fc8026741|what is the dumbe...|     0|\n",
      "|000092a90bcfbfe8cd88|can we use our ex...|     0|\n",
      "|000095680e41a9a6f6e3|i am 30, living a...|     0|\n",
      "|0000a89942e3143e333a|what do you know ...|     0|\n",
      "|0000b8e1279eaa0a7062|how difficult is ...|     0|\n",
      "|0000bc0f62500f55959f|have you licked t...|     0|\n",
      "|0000ce6c31f14d3e09ec|do you think amaz...|     0|\n",
      "|0000d329332845b8a7fa|how many baronies...|     0|\n",
      "+--------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab2(sentences, verbose =  True):\n",
    "    \"\"\"\n",
    "    :param sentences: list of list of words\n",
    "    :return: dictionary of words and their count\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "    for sentence in sentences: \n",
    "        for word in clean_text(sentence[0]).split():\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'How': 190, 'did': 23, 'Quebec': 1, 'nationalists': 1, 'see': 6}\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab2(sentences)\n",
    "print({k: vocab[k] for k in list(vocab)[:5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 94.87% of vocab\n",
      "Found embeddings for  90.14% of all text\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab,embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 300),\n",
       " ('a', 296),\n",
       " ('of', 244),\n",
       " ('and', 209),\n",
       " ('2018', 13),\n",
       " ('2017', 7),\n",
       " ('100', 6),\n",
       " ('30', 5),\n",
       " ('20', 4),\n",
       " ('10', 3)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_numbers(x):\n",
    "\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab3(sentences, verbose =  True):\n",
    "    \"\"\"\n",
    "    :param sentences: list of list of words\n",
    "    :return: dictionary of words and their count\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "    for sentence in sentences: \n",
    "        for word in clean_numbers(clean_text(sentence[0])).split():\n",
    "            try:\n",
    "                vocab[word] += 1\n",
    "            except KeyError:\n",
    "                vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'How': 190, 'did': 23, 'Quebec': 1, 'nationalists': 1, 'see': 6}\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab3(sentences)\n",
    "print({k: vocab[k] for k in list(vocab)[:5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 96.57% of vocab\n",
      "Found embeddings for  90.94% of all text\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab,embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 300),\n",
       " ('a', 296),\n",
       " ('of', 244),\n",
       " ('and', 209),\n",
       " ('organisation', 2),\n",
       " ('favourite', 2),\n",
       " ('####…', 2),\n",
       " ('kardasian', 1),\n",
       " ('licencing', 1),\n",
       " ('diffferently', 1),\n",
       " ('Kubernetes', 1),\n",
       " ('kubernetes', 1),\n",
       " ('ask…', 1),\n",
       " ('didnt', 1),\n",
       " ('lifehacks', 1),\n",
       " ('Lyft', 1),\n",
       " ('Shouldnt', 1),\n",
       " ('wrastling', 1),\n",
       " ('maintanable', 1),\n",
       " ('ॡ', 1)]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_mispell(mispell_dict):\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    return mispell_dict, mispell_re\n",
    "\n",
    "\n",
    "mispell_dict = {'colour':'color',\n",
    "                'centre':'center',\n",
    "                'didnt':'did not',\n",
    "                'doesnt':'does not',\n",
    "                'isnt':'is not',\n",
    "                'shouldnt':'should not',\n",
    "                'favourite':'favorite',\n",
    "                'travelling':'traveling',\n",
    "                'counselling':'counseling',\n",
    "                'theatre':'theater',\n",
    "                'cancelled':'canceled',\n",
    "                'labour':'labor',\n",
    "                'organisation':'organization',\n",
    "                'wwii':'world war 2',\n",
    "                'citicise':'criticize',\n",
    "                'instagram': 'social medium',\n",
    "                'whatsapp': 'social medium',\n",
    "                'snapchat': 'social medium'\n",
    "\n",
    "                }\n",
    "mispellings, mispellings_re = _get_mispell(mispell_dict)\n",
    "\n",
    "def replace_typical_misspell(text):\n",
    "    def replace(match):\n",
    "        return mispellings[match.group(0)]\n",
    "\n",
    "    return mispellings_re.sub(replace, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = ['a','to','of','and']\n",
    "\n",
    "def build_vocab4(sentences, verbose =  True):\n",
    "    \"\"\"\n",
    "    :param sentences: list of list of words\n",
    "    :return: dictionary of words and their count\n",
    "    \"\"\"\n",
    "    vocab = {}\n",
    "    for sentence in sentences: \n",
    "        for word in replace_typical_misspell(clean_numbers(clean_text(sentence[0]))).split():\n",
    "            if not word in to_remove:\n",
    "                try:\n",
    "                    vocab[word] += 1\n",
    "                except KeyError:\n",
    "                    vocab[word] = 1\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'How': 190, 'did': 24, 'Quebec': 1, 'nationalists': 1, 'see': 6}\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab4(sentences)\n",
    "print({k: vocab[k] for k in list(vocab)[:5]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found embeddings for 96.83% of vocab\n",
      "Found embeddings for  99.00% of all text\n"
     ]
    }
   ],
   "source": [
    "oov = check_coverage(vocab,embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('####…', 2),\n",
       " ('kardasian', 1),\n",
       " ('licencing', 1),\n",
       " ('diffferently', 1),\n",
       " ('Kubernetes', 1),\n",
       " ('kubernetes', 1),\n",
       " ('ask…', 1),\n",
       " ('lifehacks', 1),\n",
       " ('Lyft', 1),\n",
       " ('Shouldnt', 1),\n",
       " ('wrastling', 1),\n",
       " ('maintanable', 1),\n",
       " ('ॡ', 1),\n",
       " ('ऌ', 1),\n",
       " ('ॠ', 1),\n",
       " ('ऋ', 1),\n",
       " ('varnamala', 1),\n",
       " ('‘itll', 1),\n",
       " ('Radon–Nikodym', 1),\n",
       " ('thunderstike', 1)]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oov[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
